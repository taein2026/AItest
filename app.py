# app.py (ì‹ ë¢°ë„ ë° ê°€ë…ì„± ê°œì„  ìµœì¢… ë²„ì „)

import streamlit as st
import pandas as pd
import time
import requests
from streamlit_lottie import st_lottie
from analysis import run_analysis
import google.generativeai as genai

# --- í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(
    page_title="AI Anomaly Detection System v6.0",
    page_icon="âœ¨",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- Lottie ì• ë‹ˆë©”ì´ì…˜ ë¡œë“œ í•¨ìˆ˜ ---
@st.cache_data
def load_lottieurl(url: str):
    try:
        r = requests.get(url, timeout=10)
        if r.status_code == 200:
            return r.json()
    except requests.exceptions.RequestException:
        return None

# --- ì‚¬ì´ë“œë°” ---
with st.sidebar:
    lottie_url = "https://lottie.host/e883236e-1335-4309-a185-11a518012e69/Tpde6s5V1C.json"
    lottie_json = load_lottieurl(lottie_url)
    if lottie_json:
        st_lottie(lottie_json, speed=1, height=150, key="sidebar_lottie")

    st.title("ğŸ“„ íŒŒì¼ ì—…ë¡œë“œ")
    st.info("ë¶„ì„ì— í•„ìš”í•œ íŒŒì¼ 3ê°œë¥¼ ëª¨ë‘ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    
    uploaded_main_file = st.file_uploader("â‘  ë©”ì¸ ì§„ë£Œ ë°ì´í„°", type=['csv'])
    uploaded_disease_file = st.file_uploader("â‘¡ ìƒë³‘ëª… ë§¤ì¹­ í…Œì´ë¸”", type=['xlsx'])
    uploaded_drug_file = st.file_uploader("â‘¢ ì•½ë¬¼ëª… ë§¤ì¹­ í…Œì´ë¸”", type=['xlsx'])
    
    if uploaded_main_file and uploaded_disease_file and uploaded_drug_file:
        if st.button("âœ”ï¸ ì—…ë¡œë“œ íŒŒì¼ ì €ì¥", use_container_width=True):
            with st.spinner("íŒŒì¼ì„ ì½ê³  ìˆìŠµë‹ˆë‹¤..."):
                st.session_state['df_main'] = pd.read_csv(uploaded_main_file, encoding='cp949', low_memory=False)
                st.session_state['df_disease'] = pd.read_excel(uploaded_disease_file, dtype={'ìƒë³‘ì½”ë“œ': str})
                st.session_state['df_drug'] = pd.read_excel(uploaded_drug_file, dtype={'ì—°í•©íšŒì½”ë“œ': str})
                st.session_state['files_ready'] = True
                st.success("íŒŒì¼ ì €ì¥ ì™„ë£Œ!")

    st.markdown("---")
    start_button = st.button("ğŸš€ AI ë¶„ì„ ì‹¤í–‰", type="primary", use_container_width=True, disabled='files_ready' not in st.session_state)

# --- ë©”ì¸ í™”ë©´ ---
st.title("âœ¨ MediCopilot AI")
st.markdown("---")

if not start_button:
    st.info("â¬…ï¸ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ë¶„ì„í•  íŒŒì¼ 3ê°œë¥¼ ëª¨ë‘ ì—…ë¡œë“œí•˜ê³  'ì—…ë¡œë“œ íŒŒì¼ ì €ì¥' ë²„íŠ¼ì„ ëˆ„ë¥¸ í›„, 'AI ë¶„ì„ ì‹¤í–‰' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
    st.image("https://storage.googleapis.com/gweb-cloud-ai-generative-ai-proserve-media/images/dashboard_professional.png", use_column_width=True)

if start_button:
    if 'files_ready' in st.session_state:
        try:
            # --- AI ë¶„ì„ í”„ë¡œì„¸ìŠ¤ ë°” ---
            st.header("AI ë¶„ì„ í”„ë¡œì„¸ìŠ¤")
            
            # (ì§„í–‰ ë°” ì½”ë“œëŠ” ì´ì „ê³¼ ë™ì¼)
            step1, step2, step3, step4, step5, step6 = st.columns(6)
            placeholders = [step1.empty(), step2.empty(), step3.empty(), step4.empty(), step5.empty(), step6.empty()]
            steps = ["1. ë°ì´í„° ë¡œë”©", "2. ë°ì´í„° ì „ì²˜ë¦¬", "3. AI ëª¨ë¸ í•™ìŠµ", "4. íŒ¨í„´ ë¶„ì„", "5. ì´ìƒì¹˜ íƒì§€", "6. ë³´ê³ ì„œ ìƒì„±"]
            for i, placeholder in enumerate(placeholders):
                placeholder.info(f'**{steps[i]}**\n\n*ìƒíƒœ: â³*')
            time.sleep(0.5)
            placeholders[0].success(f'**{steps[0]}**\n\n*ìƒíƒœ: âœ… ì™„ë£Œ*')
            placeholders[1].success(f'**{steps[1]}**\n\n*ìƒíƒœ: âœ… ì™„ë£Œ*')
            
            # --- ì‹¤ì œ ë¶„ì„ ìˆ˜í–‰ ---
            df_main = st.session_state['df_main']
            df_disease = st.session_state['df_disease']
            df_drug = st.session_state['df_drug']
            results, fig, total_claims, total_anomalies = run_analysis(df_main, df_disease, df_drug)
            
            # (ì§„í–‰ ë°” ë§ˆë¬´ë¦¬)
            placeholders[2].success(f'**{steps[2]}**\n\n*ìƒíƒœ: âœ… ì™„ë£Œ*')
            placeholders[3].success(f'**{steps[3]}**\n\n*ìƒíƒœ: âœ… ì™„ë£Œ*')
            placeholders[4].success(f'**{steps[4]}**\n\n*ìƒíƒœ: âœ… ì™„ë£Œ*')
            time.sleep(0.5)
            placeholders[5].success(f'**{steps[5]}**\n\n*ìƒíƒœ: âœ… ì™„ë£Œ*')
            
            st.success("ğŸ‰ ëª¨ë“  ë¶„ì„ ê³¼ì •ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.markdown("---")
            
            # --- AI ìµœì¢… ë¶„ì„ ë¸Œë¦¬í•‘ ---
            st.header("ğŸ”¬ AI ìµœì¢… ë¶„ì„ ë¸Œë¦¬í•‘")

            try:
                genai.configure(api_key=st.secrets["GEMINI_API_KEY"])

                # --- 1. ë°ì´í„° ì‚¬ì „ ê°€ê³µ (Python-Side Pre-processing) ---
                # í†µê³„ ìˆ˜ì¹˜ë¥¼ AIì—ê²Œ ì „ë‹¬í•˜ê¸° ì „, íŒŒì´ì¬ì—ì„œ í¼ì„¼íŠ¸(%) í˜•ì‹ìœ¼ë¡œ ë¯¸ë¦¬ ë³€í™˜í•©ë‹ˆë‹¤.
                most_common_patient_id = pd.Series([res['patient_id'] for res in results]).mode()[0]
                patient_specific_reasons_str = "ìƒì„¸ ì •ë³´ ì—†ìŒ"
                for res in results:
                    if res['patient_id'] == most_common_patient_id:
                        reasons_df = res['reasons'].copy()
                        # 'í‰ê·  ì‚¬ìš©ë¥  (%)' ì»¬ëŸ¼ì„ ìƒˆë¡œ ë§Œë“¤ì–´ ë³´ê¸° ì¢‹ê²Œ í¬ë§·íŒ…í•©ë‹ˆë‹¤.
                        reasons_df['í‰ê·  ì‚¬ìš©ë¥  (%)'] = (reasons_df['í‰ê·  ì‚¬ìš©ë¥ '] * 100).map('{:.2f}%'.format)
                        # AIì—ê²Œ ì „ë‹¬í•  ì»¬ëŸ¼ë§Œ ì„ íƒí•˜ì—¬ Markdown ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
                        patient_specific_reasons_str = reasons_df[['íŠ¹ì„±ëª… (í•œê¸€)', 'í‰ê·  ì‚¬ìš©ë¥  (%)']].to_markdown(index=False)
                        break

                # --- 2. AI ê¸¸ë“¤ì´ê¸° (Advanced Prompt Engineering) ---
                prompt = f"""
                **CRITICAL INSTRUCTION: Your analysis MUST be based *strictly* on the `Input Data` provided. Do not use external medical knowledge to make definitive statements about drug interactions or clinical appropriateness. Instead, point out the statistical rarity and recommend that a human expert verify the clinical details. Your primary function is to interpret the data, not to act as a clinician.**

                **Your Role & Goal:**
                You are 'MediCopilot AI', a Multi-Disciplinary Medical AI Reviewer. Your role is to synthesize the provided data into a structured, objective report for a hospital's internal review committee.

                **Input Data:**
                - **Total Claims Analyzed:** {total_claims:,}
                - **Anomalous Patterns Detected:** {total_anomalies:,}
                - **Primary Patient of Interest:** Patient ID **{most_common_patient_id}**.
                - **Data for Patient **{most_common_patient_id}** (The 'í‰ê·  ì‚¬ìš©ë¥  (%)' column shows how often this item appears across all data):**
                ```markdown
                {patient_specific_reasons_str}
                ```

                **Mandatory Briefing Framework:**
                Generate a briefing in Korean. You MUST follow this structure precisely.

                ---

                ### ğŸ”¬ MediCopilot AI ë‹¤í•™ì œ í†µí•© ë¶„ì„ ë³´ê³ ì„œ

                #### **1. ë¶„ì„ ê°œìš” (Executive Summary)**
                * `Input Data`ì— ëª…ì‹œëœ ì´ ì§„ë£Œ ê±´ìˆ˜, ì´ìƒ íŒ¨í„´ ì‹ë³„ ê±´ìˆ˜, ê·¸ë¦¬ê³  ì£¼ìš” ê´€ì‹¬ í™˜ìë¥¼ ìš”ì•½í•©ë‹ˆë‹¤.

                #### **2. ì‹¬ì¸µ ë¶„ì„: ì£¼ìš” ê´€ì‹¬ í™˜ì (**{most_common_patient_id}**)**
                * ì´ í™˜ìê°€ í†µê³„ì ìœ¼ë¡œ ì™œ ë¶„ì„ì˜ í•µì‹¬ ëŒ€ìƒì´ ë˜ì—ˆëŠ”ì§€ `Input Data`ì— ê·¼ê±°í•˜ì—¬ ì„¤ëª…í•©ë‹ˆë‹¤.

                #### **3. ë‹¤ê°ì  ì „ë¬¸ê°€ ì˜ê²¬ (Multi-Faceted Expert Analysis)**
                * **3.1. ì„ìƒ ë° ê·œì œ ê´€ì  (Clinical & Regulatory Perspective):**
                    * **(ë°ì´í„° ê¸°ë°˜ ì„œìˆ )** 'ìƒì„¸ ì´ìƒ íŒ¨í„´ ë³´ê³ ì„œ'ì— ë”°ë¥´ë©´, ì´ í™˜ìëŠ” ì‚¬ìš©ë¥ ì´ ë§¤ìš° ë‚®ì€ í•­ëª©ë“¤ì˜ ì¡°í•©ìœ¼ë¡œ ì¹˜ë£Œë°›ì•˜ìŠµë‹ˆë‹¤.
                    * **(ì „ë¬¸ê°€ì—ê²Œ ì§ˆë¬¸ ì œê¸°)** ì´ì²˜ëŸ¼ í†µê³„ì ìœ¼ë¡œ í¬ê·€í•œ ì¡°í•©ì˜ ì˜í•™ì  íƒ€ë‹¹ì„±ê³¼ í‘œì¤€ ì§„ë£Œ ê°€ì´ë“œë¼ì¸ ë¶€í•© ì—¬ë¶€ëŠ” ë°˜ë“œì‹œ ì„ìƒ ì „ë¬¸ê°€ì˜ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì´ ì²˜ë°©ì´ ê±´ê°•ë³´í—˜ ì‹¬ì‚¬ ì‹œ ì–´ë–¤ ìŸì ì„ ìœ ë°œí•  ìˆ˜ ìˆëŠ”ì§€ ê²€í† ê°€ ìš”êµ¬ë©ë‹ˆë‹¤.

                * **3.2. ë°ì´í„° ê³¼í•™ì ê´€ì  (Data Science Perspective):**
                    * **(ëª…í™•í•œ í†µê³„ ì œì‹œ)** ì´ íŒ¨í„´ì´ í†µê³„ì  'ì´ìƒì¹˜'ë¡œ íƒì§€ëœ ì´ìœ ëŠ” `Input Data`ì˜ 'í‰ê·  ì‚¬ìš©ë¥  (%)' ìˆ˜ì¹˜ê°€ ëª…í™•íˆ ë³´ì—¬ì¤ë‹ˆë‹¤.
                    * `Input Data`ì˜ 'í‰ê·  ì‚¬ìš©ë¥  (%)'ì„ ì§ì ‘ ì¸ìš©í•˜ì—¬, í•´ë‹¹ ì¡°í•©ì´ ì „ì²´ ë°ì´í„°ì—ì„œ ì–¼ë§ˆë‚˜ ë“œë¬¼ê²Œ ë°œìƒí•˜ëŠ”ì§€ ì„¤ëª…í•˜ì„¸ìš”. (ì˜ˆ: "'A ì•½ë¬¼'ì€ ì „ì²´ ì§„ë£Œì—ì„œ ë‹¨ **0.15%**ë§Œ ì‚¬ìš©ëœ í¬ê·€ ì²˜ë°©ì…ë‹ˆë‹¤.")

                #### **4. ê·¼ë³¸ ì›ì¸ì— ëŒ€í•œ ë°ì´í„° ê¸°ë°˜ ì¶”ë¡  (Data-Driven Root Cause Hypothesis)**
                * **(ë©”íƒ€ì¸ì§€ì  ì ‘ê·¼)** ì œê³µëœ ë°ì´í„°ë§Œìœ¼ë¡œ ê·¼ë³¸ ì›ì¸ì„ í™•ì •í•  ìˆ˜ëŠ” ì—†ì§€ë§Œ, ë‹¤ìŒê³¼ ê°™ì€ ê°€ì„¤ì„ ì„¸ìš°ê³  ê²€í† ë¥¼ ì œì•ˆí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                    * **ê°€ì„¤ A (ì˜ë£Œì  íŠ¹ì´ì„±):** í™˜ìì˜ ìƒíƒœê°€ ë§¤ìš° íŠ¹ìˆ˜í•˜ì—¬ ì´ë¡€ì ì¸ ì²˜ë°©ì´ í•„ìš”í–ˆì„ ê°€ëŠ¥ì„±. ì´ëŠ” `Input Data`ë§Œìœ¼ë¡œëŠ” ê²€ì¦ì´ ë¶ˆê°€ëŠ¥í•˜ë©°, ìƒì„¸í•œ ì˜ë¬´ê¸°ë¡ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.
                    * **ê°€ì„¤ B (í–‰ì •ì  ì˜¤ë¥˜):** ì²­êµ¬ ì½”ë“œ ì…ë ¥ ì‹¤ìˆ˜ ë“±ì˜ ì˜¤ë¥˜ ê°€ëŠ¥ì„±. ë°ì´í„°ì˜ í†µê³„ì  í¬ê·€ì„±ì´ ë§¤ìš° ë†’ì„ ê²½ìš°, ì´ ê°€ì„¤ì˜ ê²€í†  ìš°ì„ ìˆœìœ„ê°€ ë†’ì•„ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

                #### **5. ìµœì¢… ê¶Œê³  ë° ì œì–¸ (Final Recommendations & Limitations)**
                * 1. **(ì˜ë¬´ê¸°ë¡ ëŒ€ì¡°)** í™˜ì **{most_common_patient_id}**ì˜ ìƒì„¸ ì˜ë¬´ê¸°ë¡ì„ `Input Data`ì™€ ëŒ€ì¡°í•˜ì—¬ ì‚¬ì‹¤ê´€ê³„ë¥¼ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤.
                * 2. **(ì „ë¬¸ê°€ ê²€í†  ì˜ë¢°)** í†µê³„ì ìœ¼ë¡œ ì´ë¡€ì ì¸ ì´ ì²˜ë°© ì¡°í•©ì˜ ì˜í•™ì  ì ì •ì„±ì— ëŒ€í•œ ì„ìƒ ì „ë¬¸ê°€ì˜ ê³µì‹ì ì¸ ê²€í† ë¥¼ ìš”ì²­í•´ì•¼ í•©ë‹ˆë‹¤.
                * 3. **(ë°ì´í„° ì…ë ¥ í”„ë¡œì„¸ìŠ¤ ì ê²€)** í–‰ì •ì  ì˜¤ë¥˜ ê°€ëŠ¥ì„±ì„ ë°°ì œí•˜ê¸° ìœ„í•´, í•´ë‹¹ ì§„ë£Œ ê±´ì˜ ë°ì´í„° ì…ë ¥ ê³¼ì •ì„ ì ê²€í•  ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.
                * **(ëª…í™•í•œ í•œê³„ ê³ ì§€)** **ë³¸ AI ë³´ê³ ì„œëŠ” í†µê³„ì  ì´ìƒ íŒ¨í„´ì„ ì‹ë³„í•˜ëŠ” ë³´ì¡° ë„êµ¬ì´ë©°, ì˜ë£Œ í–‰ìœ„ì˜ ì ì •ì„±ì„ ìµœì¢… íŒë‹¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ëª¨ë“  ê²°ë¡ ì€ ë°˜ë“œì‹œ í•´ë‹¹ ë¶„ì•¼ì˜ ì¸ê°„ ì „ë¬¸ê°€ì— ì˜í•´ ê²€í† ë˜ê³  í™•ì¦ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.**

                ---
                """
                
                model = genai.GenerativeModel('gemini-1.5-flash')
                response = model.generate_content(prompt, stream=True)

                with st.chat_message("ai", avatar="ğŸ¤–"):
                    report_placeholder = st.empty()
                    full_response = ""
                    for chunk in response:
                        full_response += chunk.text
                        report_placeholder.markdown(full_response + "â–Œ", unsafe_allow_html=True)
                    report_placeholder.markdown(full_response, unsafe_allow_html=True)

            except Exception as e:
                st.error(f"AI ë¸Œë¦¬í•‘ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            
            # --- ëŒ€ì‹œë³´ë“œ ë° ìƒì„¸ ë¶„ì„ í…Œì´ë¸” (ì´ì „ê³¼ ë™ì¼) ---
            st.markdown("---")
            st.header("ë¶„ì„ ê²°ê³¼ ìƒì„¸ ëŒ€ì‹œë³´ë“œ")
            col1, col2, col3 = st.columns(3)
            col1.metric("ì´ ì§„ë£Œ ê±´ìˆ˜", f"{total_claims:,} ê±´")
            col2.metric("íƒì§€ëœ ì´ìƒì¹˜", f"{total_anomalies:,} ê±´", f"ìƒìœ„ {(total_anomalies/total_claims):.2%}")
            col3.metric("ë¶„ì„ëœ íŠ¹ì„±(í•­ëª©) ìˆ˜", "500+ ê°œ") 
            tab1, tab2 = st.tabs(["ğŸ“Š **ì´ìƒì¹˜ ìš”ì•½ ë° ê·¸ë˜í”„**", "ğŸ“‘ **Top 20 ìƒì„¸ ë¶„ì„**"])
            with tab1:
                st.subheader("ì´ìƒì¹˜ ë¶„í¬ ì‹œê°í™”")
                st.info("íŒŒë€ìƒ‰ ì ë“¤ì€ ì¼ë°˜ì ì¸ ì§„ë£Œ íŒ¨í„´ì„, ë¹¨ê°„ìƒ‰ ì ë“¤ì€ AIê°€ í†µê³„ì ìœ¼ë¡œ íŠ¹ì´í•˜ë‹¤ê³  íŒë‹¨í•œ ì´ìƒì¹˜ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.")
                st.plotly_chart(fig, use_container_width=True)
            with tab2:
                st.subheader("ê°€ì¥ ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ì§„ë£Œ Top 20")
                st.info("Rankê°€ ë†’ì„ìˆ˜ë¡ íŒ¨í„´ì´ ì´ì§ˆì ì´ë¼ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤. ê° í•­ëª©ì„ í´ë¦­í•˜ì—¬ ìƒì„¸ ì›ì¸ì„ í™•ì¸í•˜ì„¸ìš”.")
                for res in reversed(results):
                    expander_title = f"**Rank {res['rank']}** | í™˜ìë²ˆí˜¸: `{res['patient_id']}` | ì§„ë£Œì¼: `{res['date']}`"
                    with st.expander(expander_title):
                        st.write("â–¶ **ì´ ì§„ë£Œê°€ ì´ìƒì¹˜ë¡œ íŒë‹¨ëœ í•µì‹¬ ì´ìœ  (ê°€ì¥ í¬ê·€í•œ ì¡°í•© Top 5):**")
                        st.dataframe(res['reasons'], use_container_width=True) 

        except Exception as e:
            st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            st.exception(e)
    else:
        st.warning("ğŸš¨ ë¶„ì„ì„ ì‹œì‘í•˜ê¸° ì „ì— ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ íŒŒì¼ 3ê°œë¥¼ ëª¨ë‘ ì—…ë¡œë“œí•˜ê³  'ì—…ë¡œë“œ íŒŒì¼ ì €ì¥' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”!")
