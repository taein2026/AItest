# app.py (íƒ€ì´í•‘ íš¨ê³¼ ë³µêµ¬ ìµœì¢… ë²„ì „)

import streamlit as st
import pandas as pd
import time
import requests
from streamlit_lottie import st_lottie
from analysis import run_analysis

# --- í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(
    page_title="AI Anomaly Detection System v3.0",
    page_icon="ğŸ§ ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- Lottie ì• ë‹ˆë©”ì´ì…˜ ë¡œë“œ í•¨ìˆ˜ ---
@st.cache_data
def load_lottieurl(url: str):
    try:
        r = requests.get(url, timeout=10)
        if r.status_code == 200:
            return r.json()
    except requests.exceptions.RequestException:
        return None

# --- ì‚¬ì´ë“œë°” ---
with st.sidebar:
    lottie_url = "https://lottie.host/e883236e-1335-4309-a185-11a518012e69/Tpde6s5V1C.json"
    lottie_json = load_lottieurl(lottie_url)
    if lottie_json:
        st_lottie(lottie_json, speed=1, height=150, key="sidebar_lottie")

    st.title("ğŸ“„ íŒŒì¼ ì—…ë¡œë“œ")
    st.info("ë¶„ì„ì— í•„ìš”í•œ íŒŒì¼ 3ê°œë¥¼ ëª¨ë‘ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    
    uploaded_main_file = st.file_uploader("â‘  ë©”ì¸ ì§„ë£Œ ë°ì´í„°", type=['csv'])
    uploaded_disease_file = st.file_uploader("â‘¡ ìƒë³‘ëª… ë§¤ì¹­ í…Œì´ë¸”", type=['xlsx'])
    uploaded_drug_file = st.file_uploader("â‘¢ ì•½ë¬¼ëª… ë§¤ì¹­ í…Œì´ë¸”", type=['xlsx'])
    
    if uploaded_main_file and uploaded_disease_file and uploaded_drug_file:
        st.session_state['files_ready'] = True

    st.markdown("---")
    start_button = st.button("ğŸš€ AI ë¶„ì„ ì‹¤í–‰", type="primary", use_container_width=True, disabled='files_ready' not in st.session_state)

# --- ë©”ì¸ í™”ë©´ ---
st.title("ğŸ§  AI ì´ìƒ ì§„ë£Œ íƒì§€ ì‹œìŠ¤í…œ v3.0")
st.markdown("---")

# ì´ˆê¸° í™”ë©´
if not start_button:
    st.info("â¬…ï¸ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ë¶„ì„í•  íŒŒì¼ 3ê°œë¥¼ ëª¨ë‘ ì—…ë¡œë“œí•˜ê³ , 'AI ë¶„ì„ ì‹¤í–‰' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
    st.image("https://storage.googleapis.com/gweb-cloud-ai-generative-ai-proserve-media/images/dashboard_professional.png", use_column_width=True)

# ë¶„ì„ ì‹œì‘
if start_button:
    if 'files_ready' in st.session_state:
        try:
            # --- AI ë¶„ì„ í”„ë¡œì„¸ìŠ¤ ë°” ---
            st.header("AI ë¶„ì„ í”„ë¡œì„¸ìŠ¤")
            step1, step2, step3, step4 = st.columns(4)
            s1_placeholder, s2_placeholder, s3_placeholder, s4_placeholder = step1.empty(), step2.empty(), step3.empty(), step4.empty()
            placeholders = [s1_placeholder, s2_placeholder, s3_placeholder, s4_placeholder]
            steps = ["1. ë°ì´í„° ë¡œë”©", "2. ë°ì´í„° í•™ìŠµ", "3. ì´ìƒì¹˜ íƒì§€", "4. ë³´ê³ ì„œ ìƒì„±"]

            for i, placeholder in enumerate(placeholders):
                placeholder.info(f'**{steps[i]}**\n\n*ìƒíƒœ: â³ ëŒ€ê¸° ì¤‘*')

            time.sleep(1)
            s1_placeholder.info(f'**{steps[0]}**\n\n*ìƒíƒœ: âš™ï¸ ì§„í–‰ ì¤‘...*')
            df_main = pd.read_csv(uploaded_main_file, encoding='cp949', low_memory=False)
            df_disease = pd.read_excel(uploaded_disease_file, dtype={'ìƒë³‘ì½”ë“œ': str})
            df_drug = pd.read_excel(uploaded_drug_file, dtype={'ì—°í•©íšŒì½”ë“œ': str})
            time.sleep(1.5)
            s1_placeholder.success(f'**{steps[0]}**\n\n*ìƒíƒœ: âœ… ì™„ë£Œ*')

            s2_placeholder.info(f'**{steps[1]}**\n\n*ìƒíƒœ: âš™ï¸ ì§„í–‰ ì¤‘...*')
            results, fig, total_claims, total_anomalies = run_analysis(df_main, df_disease, df_drug)
            s2_placeholder.success(f'**{steps[1]}**\n\n*ìƒíƒœ: âœ… ì™„ë£Œ*')

            s3_placeholder.info(f'**{steps[2]}**\n\n*ìƒíƒœ: âš™ï¸ ì§„í–‰ ì¤‘...*')
            time.sleep(2)
            s3_placeholder.success(f'**{steps[2]}**\n\n*ìƒíƒœ: âœ… ì™„ë£Œ*')

            s4_placeholder.info(f'**{steps[3]}**\n\n*ìƒíƒœ: âš™ï¸ ì§„í–‰ ì¤‘...*')
            time.sleep(1.5)
            s4_placeholder.success(f'**{steps[3]}**\n\n*ìƒíƒœ: âœ… ì™„ë£Œ*')
            
            st.success("ğŸ‰ ëª¨ë“  ë¶„ì„ ê³¼ì •ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.markdown("---")

            # --- AI ìµœì¢… ë¶„ì„ ë¸Œë¦¬í•‘ (íƒ€ì´í•‘ íš¨ê³¼ ì ìš©) ---
            st.header("ğŸ”¬ AI ìµœì¢… ë¶„ì„ ë¸Œë¦¬í•‘")
            
            def stream_text(text_to_stream):
                placeholder = st.empty()
                full_response = ""
                for chunk in text_to_stream:
                    full_response += chunk
                    time.sleep(0.015)
                    placeholder.markdown(full_response + "â–Œ", unsafe_allow_html=True)
                placeholder.markdown(full_response, unsafe_allow_html=True)

            patient_ids = [res['patient_id'] for res in results]
            if patient_ids:
                most_common_patient = pd.Series(patient_ids).mode()[0]
                count = patient_ids.count(most_common_patient)
                key_finding = f"ê°€ì¥ ì£¼ëª©í•  ë§Œí•œ íŒ¨í„´ì€ íŠ¹ì • í™˜ìì—ê²Œì„œ ì´ìƒì¹˜ê°€ ì§‘ì¤‘ì ìœ¼ë¡œ ë°œê²¬ëœ ì ì…ë‹ˆë‹¤. íŠ¹íˆ **í™˜ìë²ˆí˜¸ `{most_common_patient}`**ëŠ” Top 20 ë¦¬ìŠ¤íŠ¸ì— <span style='color: #00f4d4;'>**{count}íšŒ**</span> ë“±ì¥í•˜ì—¬, í•´ë‹¹ í™˜ìì˜ ì§„ë£Œ ì´ë ¥ì— ëŒ€í•œ ì‹¬ì¸µ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤."
            else:
                key_finding = "íƒì§€ëœ ì´ìƒì¹˜ ì¤‘ì—ì„œ íŠ¹ë³„íˆ ì§‘ì¤‘ë˜ëŠ” íŒ¨í„´ì€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            
            summary_text = f"> **ë¶„ì„ ìš”ì•½:** ì´ <span style='color: #00f4d4;'>**{total_claims:,}**</span>ê±´ì˜ ì§„ë£Œ ê¸°ë¡ì„ ë¶„ì„í•˜ì—¬, <span style='color: #00f4d4;'>**{total_anomalies:,}**</span>ê±´ì˜ í†µê³„ì  ì´ìƒ íŒ¨í„´ì„ ì‹ë³„í–ˆìŠµë‹ˆë‹¤."
            finding_text = f"> **í•µì‹¬ ë°œê²¬:** {key_finding}"
            recommendation_text = f"> **ê¶Œì¥ ì¡°ì¹˜:** ì´ìƒì¹˜ë¡œ íƒì§€ëœ ì§„ë£Œ ê±´ë“¤ì˜ ìƒì„¸ ë¶„ì„ì„ í†µí•´, ì´ë¡€ì ì¸ ì²˜ë°©/ì§„ë‹¨ ì¡°í•©ì˜ ì˜í•™ì  íƒ€ë‹¹ì„±ì„ í™•ì¸í•˜ì‹­ì‹œì˜¤."
            
            full_briefing_text = f"{summary_text}\n\n{finding_text}\n\n{recommendation_text}"
            stream_text(full_briefing_text)
            
            st.markdown("---")
            
            # --- ë¶„ì„ ê²°ê³¼ ìƒì„¸ ëŒ€ì‹œë³´ë“œ ---
            st.header("ë¶„ì„ ê²°ê³¼ ìƒì„¸ ëŒ€ì‹œë³´ë“œ")
            col1, col2, col3 = st.columns(3)
            col1.metric("ì´ ì§„ë£Œ ê±´ìˆ˜", f"{total_claims:,} ê±´")
            col2.metric("íƒì§€ëœ ì´ìƒì¹˜", f"{total_anomalies:,} ê±´", f"ìƒìœ„ {(total_anomalies/total_claims):.2%}")
            col3.metric("ë¶„ì„ëœ íŠ¹ì„±(í•­ëª©) ìˆ˜", "500 ê°œ")
            
            tab1, tab2 = st.tabs(["ğŸ“Š **ì´ìƒì¹˜ ìš”ì•½ ë° ê·¸ë˜í”„**", "ğŸ“‘ **Top 20 ìƒì„¸ ë¶„ì„**"])
            with tab1:
                st.subheader("ì´ìƒì¹˜ ë¶„í¬ ì‹œê°í™”")
                st.info("íŒŒë€ìƒ‰ ì ë“¤ì€ ì¼ë°˜ì ì¸ ì§„ë£Œ íŒ¨í„´ì„, ë¹¨ê°„ìƒ‰ ì ë“¤ì€ AIê°€ í†µê³„ì ìœ¼ë¡œ íŠ¹ì´í•˜ë‹¤ê³  íŒë‹¨í•œ ì´ìƒì¹˜ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.")
                st.plotly_chart(fig, use_container_width=True)
            with tab2:
                st.subheader("ê°€ì¥ ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ì§„ë£Œ Top 20")
                st.info("Rankê°€ ë†’ì„ìˆ˜ë¡ íŒ¨í„´ì´ ì´ì§ˆì ì´ë¼ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤. ê° í•­ëª©ì„ í´ë¦­í•˜ì—¬ ìƒì„¸ ì›ì¸ì„ í™•ì¸í•˜ì„¸ìš”.")
                for res in reversed(results):
                    expander_title = f"**Rank {res['rank']}** | í™˜ìë²ˆí˜¸: `{res['patient_id']}` | ì§„ë£Œì¼: `{res['date']}`"
                    with st.expander(expander_title):
                        st.write("â–¶ **ì´ ì§„ë£Œê°€ ì´ìƒì¹˜ë¡œ íŒë‹¨ëœ í•µì‹¬ ì´ìœ  (ê°€ì¥ í¬ê·€í•œ ì¡°í•© Top 5):**")
                        st.dataframe(res['reasons'], use_container_width=True) 
                        
        except Exception as e:
            st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            st.exception(e)
    else:
        st.warning("ğŸš¨ ë¶„ì„ì„ ì‹œì‘í•˜ê¸° ì „ì— ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ íŒŒì¼ 3ê°œë¥¼ ëª¨ë‘ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”!")
